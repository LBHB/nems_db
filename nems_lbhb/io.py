#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Sep 18 16:47:56 2018

@author: svd
"""

import logging
import re
import os
import os.path
import scipy.io
import scipy.ndimage.filters
import scipy.signal
import numpy as np
import json
import sys
import io
import datetime
import glob
from math import isclose
import copy

import pandas as pd
import matplotlib.pyplot as plt
import nems.signal
import nems.recording
import nems_db.db as db
from nems.recording import Recording
from nems.recording import load_recording


# TODO: Replace catch-all `except:` statements with except SpecificError,
#       or add some other way to help with debugging them.

# paths to baphy data -- standard locations on elephant
stim_cache_dir = '/auto/data/tmp/tstim/'  # location of cached stimuli
spk_subdir = 'sorted/'   # location of spk.mat files relative to parmfiles

# TODO: Replace print() statements with log.info()?
log = logging.getLogger(__name__)


def baphy_mat2py(s):

    s3 = re.sub(r';', r'', s.rstrip())
    s3 = re.sub(r'%', r'#', s3)
    s3 = re.sub(r'\\', r'/', s3)
    s3 = re.sub(r"\.([a-zA-Z0-9]+)'", r"XX\g<1>'", s3)
    s3 = re.sub(r"\.([a-zA-Z0-9]+)\+", r"XX\g<1>+", s3)
    s3 = re.sub(r"\.([a-zA-Z0-9]+) ,", r"XX\g<1> ,", s3)
    s3 = re.sub(r'globalparams\(1\)', r'globalparams', s3)
    s3 = re.sub(r'exptparams\(1\)', r'exptparams', s3)

    s4 = re.sub(r'\(([0-9]*)\)', r'[\g<1>]', s3)

    s5 = re.sub(r'\.([A-Za-z][A-Za-z0-9_]+)', r"['\g<1>']", s4)

    s6 = re.sub(r'([0-9]+) ', r"\g<0>,", s5)
    s6 = re.sub(r'NaN ', r"np.nan,", s6)
    s6 = re.sub(r'Inf ', r"np.inf,", s6)

    s7 = re.sub(r"XX([a-zA-Z0-9]+)'", r".\g<1>'", s6)
    s7 = re.sub(r"XX([a-zA-Z0-9]+)\+", r".\g<1>+", s7)
    s7 = re.sub(r"XX([a-zA-Z0-9]+) ,", r".\g<1> ,", s7)
    s7 = re.sub(r',,', r',', s7)
    s7 = re.sub(r',Hz', r'Hz', s7)
    s7 = re.sub(r'NaN', r'np.nan', s7)
    s7 = re.sub(r'zeros\(([0-9,]+)\)', r'np.zeros([\g<1>])', s7)
    s7 = re.sub(r'{(.*)}', r'[\g<1>]', s7)

    return s7


def baphy_parm_read(filepath):
    print("Loading {0}".format(filepath))

    f = io.open(filepath, "r")
    s = f.readlines(-1)

    globalparams = {}
    exptparams = {}
    exptevents = {}

    for ts in s:
        sout = baphy_mat2py(ts)
        # print(sout)
        try:
            exec(sout)
        except KeyError:
            ts1 = sout.split('= [')
            ts1 = ts1[0].split(',[')

            s1 = ts1[0].split('[')
            sout1 = "[".join(s1[:-1]) + ' = {}'
            try:
                exec(sout1)
            except:
                s2 = sout1.split('[')
                sout2 = "[".join(s2[:-1]) + ' = {}'
                try:
                    exec(sout2)
                except:
                    s3 = sout2.split('[')
                    sout3 = "[".join(s3[:-1]) + ' = {}'
                    exec(sout3)
                    exec(sout2)

                exec(sout1)
            exec(sout)
        except NameError:
            print("NameError on: {0}".format(sout))
        except:
            print("Other error on: {0} to {1}".format(ts,sout))

    # special conversions

    # convert exptevents to a DataFrame:
    t = [exptevents[k] for k in exptevents]
    d = pd.DataFrame(t)
    if 'ClockStartTime' in d.columns:
        exptevents = d.drop(['Rove', 'ClockStartTime'], axis=1)
    else:
        exptevents = d.drop(['Rove'], axis=1)

    # rename columns to NEMS standard epoch names
    exptevents.columns = ['name', 'start', 'end', 'Trial']
    for i in range(len(exptevents)):
        if exptevents.loc[i, 'end'] == []:
            exptevents.loc[i, 'end'] = exptevents.loc[i, 'start']

    return globalparams, exptparams, exptevents


def baphy_load_specgram(stimfilepath):

    matdata = scipy.io.loadmat(stimfilepath, chars_as_strings=True)

    stim = matdata['stim']

    stimparam = matdata['stimparam'][0][0]

    try:
        # case 1: loadstimfrombaphy format
        # remove redundant tags from tag list and stimulus array
        d = matdata['stimparam'][0][0][0][0]
        d = [x[0] for x in d]
        tags, tagids = np.unique(d, return_index=True)

        stim = stim[:, :, tagids]
    except:
        # loadstimbytrial format. don't want to filter by unique tags.
        # field names within stimparam don't seem to be preserved
        # in this load format??
        d = matdata['stimparam'][0][0][2][0]
        tags = [x[0] for x in d]

    return stim, tags, stimparam


def baphy_stim_cachefile(exptparams, parmfilepath=None, **options):
    """
    generate cache filename generated by loadstimfrombaphy

    code adapted from loadstimfrombaphy.m
    """

    if 'truncatetargets' not in options:
        options['truncatetargets'] = 1
    if 'pertrial' not in options:
        options['pertrial'] = False

    if options['pertrial']:
        # loadstimbytrial cache filename format
        pp, bb = os.path.split(parmfilepath)
        bb = bb.split(".")[0]
        dstr = "loadstimbytrial_{0}_ff{1}_fs{2}_cc{3}_trunc{4}.mat".format(
                     bb, options['stimfmt'], options['rasterfs'],
                     options['chancount'], options['truncatetargets']
                     )
        return stim_cache_dir + dstr

    # otherwise use standard load stim from baphy format
    if options['runclass'] is None:
        RefObject = exptparams['TrialObject'][1]['ReferenceHandle'][1]
    elif 'runclass' in exptparams.keys():
        runclass = exptparams['runclass'].split("_")
        if (len(runclass) > 1) and (runclass[1] == options["runclass"]):
            RefObject = exptparams['TrialObject'][1]['TargetHandle'][1]
        else:
            RefObject = exptparams['TrialObject'][1]['ReferenceHandle'][1]
    else:
        RefObject = exptparams['TrialObject'][1]['ReferenceHandle'][1]

    dstr = RefObject['descriptor']
    if dstr == 'Torc':
        if 'RunClass' in exptparams['TrialObject'][1].keys():
            dstr += '-'+exptparams['TrialObject'][1]['RunClass']
        else:
            dstr += '-TOR'

    # include all parameter values, even defaults, in filename
    fields = RefObject['UserDefinableFields']
    for cnt1 in range(0, len(fields), 3):
        if RefObject[fields[cnt1]] == 0:
            RefObject[fields[cnt1]] = int(0)
            # print(fields[cnt1])
            # print(RefObject[fields[cnt1]])
            # print(dstr)
        dstr = "{0}-{1}".format(dstr, RefObject[fields[cnt1]])

    dstr = re.sub(r":", r"", dstr)

    if 'OveralldB' in exptparams['TrialObject'][1]:
        OveralldB = exptparams['TrialObject'][1]['OveralldB']
        dstr += "-{0}dB".format(OveralldB)
    else:
        OveralldB = 0

    dstr += "-{0}-fs{1}-ch{2}".format(
            options['stimfmt'], options['rasterfs'], options['chancount']
            )

    if options['includeprestim']:
        dstr += '-incps1'

    dstr = re.sub(r"[ ,]", r"_", dstr)
    dstr = re.sub(r"[\[\]]", r"", dstr)

    return stim_cache_dir + dstr + '.mat'


def baphy_load_spike_data_raw(spkfilepath, channel=None, unit=None):

    matdata = scipy.io.loadmat(spkfilepath, chars_as_strings=True)

    sortinfo = matdata['sortinfo']
    if sortinfo.shape[0] > 1:
        sortinfo = sortinfo.T
    sortinfo = sortinfo[0]

    # figure out sampling rate, used to convert spike times into seconds
    spikefs = matdata['rate'][0][0]

    return sortinfo, spikefs


def baphy_align_time(exptevents, sortinfo, spikefs, finalfs=0):

    # number of channels in recording (not all necessarily contain spikes)
    chancount = len(sortinfo)

    # figure out how long each trial is by the time of the last spike count.
    # this method is a hack!
    # but since recordings are longer than the "official"
    # trial end time reported by baphy, this method preserves extra spikes
    TrialCount = np.max(exptevents['Trial'])
    TrialLen_sec = np.array(
            exptevents.loc[exptevents['name'] == "TRIALSTOP"]['start']
            )
    TrialLen_spikefs = np.concatenate(
            (np.zeros([1, 1]), TrialLen_sec[:, np.newaxis]*spikefs), axis=0
            )

    for c in range(0, chancount):
        if len(sortinfo[c]) and sortinfo[c][0].size:
            s = sortinfo[c][0][0]['unitSpikes']
            s = np.reshape(s, (-1, 1))
            unitcount = s.shape[0]
            for u in range(0, unitcount):
                st = s[u, 0]

                # print('chan {0} unit {1}: {2} spikes'.format(c,u,st.shape[1]))
                for trialidx in range(1, TrialCount+1):
                    ff = (st[0, :] == trialidx)
                    if np.sum(ff):
                        utrial_spikefs = np.max(st[1, ff])
                        TrialLen_spikefs[trialidx, 0] = np.max(
                                [utrial_spikefs, TrialLen_spikefs[trialidx, 0]]
                                )

    # using the trial lengths, figure out adjustments to trial event times.
    if finalfs:
        print('rounding Trial offset spike times'
              ' to even number of rasterfs bins')
        # print(TrialLen_spikefs)
        TrialLen_spikefs = (
                np.ceil(TrialLen_spikefs / spikefs*finalfs)
                / finalfs*spikefs
                )
        # print(TrialLen_spikefs)

    Offset_spikefs = np.cumsum(TrialLen_spikefs)
    Offset_sec = Offset_spikefs / spikefs  # how much to offset each trial

    # adjust times in exptevents to approximate time since experiment started
    # rather than time since trial started (native format)
    for Trialidx in range(1, TrialCount+1):
        # print("Adjusting trial {0} by {1} sec"
        #       .format(Trialidx,Offset_sec[Trialidx-1]))
        ff = (exptevents['Trial'] == Trialidx)
        exptevents.loc[ff, ['start', 'end']] = (
                exptevents.loc[ff, ['start', 'end']] + Offset_sec[Trialidx-1]
                )

        # ff = ((exptevents['Trial'] == Trialidx)
        #       & (exptevents['end'] > Offset_sec[Trialidx]))
        # badevents, = np.where(ff)
        # print("{0} events past end of trial?".format(len(badevents)))
        # exptevents.drop(badevents)

    print("{0} trials totaling {1:.2f} sec".format(TrialCount, Offset_sec[-1]))

    # convert spike times from samples since trial started to
    # (approximate) seconds since experiment started (matched to exptevents)
    totalunits = 0
    spiketimes = []  # list of spike event times for each unit in recording
    unit_names = []  # string suffix for each unit (CC-U)
    chan_names = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']
    for c in range(0, chancount):
        if len(sortinfo[c]) and sortinfo[c][0].size:
            s = sortinfo[c][0][0]['unitSpikes']
            comment = sortinfo[c][0][0][0][0][2][0]
            log.debug('Comment: %s', comment)

            s = np.reshape(s, (-1, 1))
            unitcount = s.shape[0]
            for u in range(0, unitcount):
                st = s[u, 0]
                uniquetrials = np.unique(st[0, :])
                # print('chan {0} unit {1}: {2} spikes {3} trials'
                #       .format(c, u, st.shape[1], len(uniquetrials)))

                unit_spike_events = np.array([])
                for trialidx in uniquetrials:
                    ff = (st[0, :] == trialidx)
                    this_spike_events = (st[1, ff]
                                         + Offset_spikefs[np.int(trialidx-1)])
                    if comment == 'PC-cluster sorted by mespca.m':
                        # remove last spike, which is stray
                        this_spike_events = this_spike_events[:-1]
                    unit_spike_events = np.concatenate(
                            (unit_spike_events, this_spike_events), axis=0
                            )
                    # print("   trial {0} first spike bin {1}"
                    #       .format(trialidx,st[1,ff]))

                totalunits += 1
                if chancount <= 8:
                    unit_names.append("{0}{1}".format(chan_names[c], u+1))
                else:
                    unit_names.append("{0:02d}-{1}".format(c+1, u+1))
                spiketimes.append(unit_spike_events / spikefs)

    return exptevents, spiketimes, unit_names


def baphy_load_pupil_trace_standalone(pupilfilepath, exptevents=None, **options):
    """
    returns big_rs which is pupil trace resampled to options['rasterfs']
    and strialidx, which is the index into big_rs for the start of each
    trial. need to make sure the big_rs vector aligns with the other signals
    """

    rasterfs = options.get('rasterfs', 100)
    pupil_offset = options.get('pupil_offset', 0.75)
    pupil_deblink = options.get('pupil_deblink', True)
    pupil_deblink_dur = options.get('pupil_deblink_dur', (1/3))
    pupil_median = options.get('pupil_median', 0)
    pupil_smooth = options.get('pupil_smooth', 0)
    pupil_highpass = options.get('pupil_highpass', 0)
    pupil_lowpass = options.get('pupil_lowpass', 0)
    pupil_bandpass = options.get('pupil_bandpass', 0)
    pupil_derivative = options.get('pupil_derivative', '')
    pupil_mm = options.get('pupil_mm', False)
    pupil_eyespeed = options.get('pupil_eyespeed', False)
    verbose = options.get('verbose', False)

    if exptevents is None:
        parmfilepath = pupilfilepath.replace(".pup.mat",".m")
        globalparams, exptparams, exptevents = baphy_parm_read(parmfilepath)
        pp, bb = os.path.split(parmfilepath)
        spkfilepath = pp + '/' + spk_subdir + re.sub(r"\.m$", ".spk.mat", bb)
        print("Spike file: {0}".format(spkfilepath))
        # load spike times
        sortinfo, spikefs = baphy_load_spike_data_raw(spkfilepath)
        # adjust spike and event times to be in seconds since experiment started
        exptevents, spiketimes, unit_names = baphy_align_time(
                exptevents, sortinfo, spikefs, rasterfs
                )

    if pupil_smooth:
        raise ValueError('pupil_smooth not implemented. try pupil_median?')
    if pupil_highpass:
        raise ValueError('pupil_highpass not implemented.')
    if pupil_lowpass:
        raise ValueError('pupil_lowpass not implemented.')
    if pupil_bandpass:
        raise ValueError('pupil_bandpass not implemented.')
    if pupil_derivative:
        raise ValueError('pupil_derivative not implemented.')

    matdata = scipy.io.loadmat(pupilfilepath)

    p = matdata['pupil_data']
    params = p['params']
    if 'pupil_variable_name' not in options:
        options['pupil_variable_name'] = params[0][0]['default_var'][0][0][0]
        print("Using default pupil_variable_name: " +
              options['pupil_variable_name'])
    if 'pupil_algorithm' not in options:
        options['pupil_algorithm'] = params[0][0]['default'][0][0][0]
        print("Using default pupil_algorithm: " + options['pupil_algorithm'])

    results = p['results'][0][0][-1][options['pupil_algorithm']]
    pupil_diameter = np.array(results[0][options['pupil_variable_name']][0][0])
    if pupil_diameter.shape[0] == 1:
        pupil_diameter = pupil_diameter.T
    print("pupil_diameter.shape: " + str(pupil_diameter.shape))

    if pupil_eyespeed:
        eye_speed = np.array(results[0]['eye_speed'][0][0])

    fs_approximate = 30  # approx video framerate
    if pupil_deblink:
        dp = np.abs(np.diff(pupil_diameter, axis=0))
        blink = np.zeros(dp.shape)
        blink[dp > np.nanmean(dp) + 6*np.nanstd(dp)] = 1
        # CRH add following line 7-19-2019
        # (blink should be = 1 if pupil_dia goes to 0)
        blink[[isclose(p, 0, abs_tol=0.5) for p in pupil_diameter[:-1]]] = 1
        smooth_width = int(fs_approximate*pupil_deblink_dur)
        box = np.ones([smooth_width]) / smooth_width
        blink = np.convolve(blink[:, 0], box, mode='same')
        blink[blink > 0] = 1
        blink[blink <= 0] = 0
        onidx, = np.where(np.diff(blink) > 0)
        offidx, = np.where(np.diff(blink) < 0)

        if onidx[0] > offidx[0]:
            onidx = np.concatenate((np.array([0]), onidx))
        if len(onidx) > len(offidx):
            offidx = np.concatenate((offidx, np.array([len(blink)])))
        deblinked = pupil_diameter.copy()
        if pupil_eyespeed:
            deblinked_eye_speed = eye_speed.copy()
        for i, x1 in enumerate(onidx):
            x2 = offidx[i]
            if x2 < x1:
                print([i, x1, x2])
                print("WHAT'S UP??")
            else:
                # print([i,x1,x2])
                deblinked[x1:x2, 0] = np.linspace(
                        deblinked[x1], deblinked[x2-1], x2-x1
                        )
                if pupil_eyespeed:
                    deblinked_eye_speed[x1:x2, 0] = np.nan

        if verbose:
            plt.figure()
            if pupil_eyespeed:
                plt.subplot(2,1,1)
            plt.plot(pupil_diameter, label='Raw')
            plt.plot(deblinked, label='Deblinked')
            plt.xlabel('Frame')
            plt.ylabel('Pupil')
            plt.legend()
            plt.title("Artifacts detected: {}".format(len(onidx)))
            if pupil_eyespeed:
                plt.subplot(2,1,2)
                plt.plot(eye_speed, label='Raw')
                plt.plot(deblinked_eye_speed, label='Deblinked')
                plt.xlabel('Frame')
                plt.ylabel('Eye speed')
                plt.legend()
        pupil_diameter = deblinked
        if pupil_eyespeed:
            eye_speed = deblinked_eye_speed

    if pupil_eyespeed:
        returned_measurement = eye_speed
    else:
        returned_measurement = pupil_diameter

    # resample and remove dropped frames

    # find and parse pupil events
    pp = ['PUPIL,' in x['name'] for i, x in exptevents.iterrows()]
    trials = list(exptevents.loc[pp, 'Trial'])
    ntrials = len(trials)
    timestamp = np.zeros([ntrials+1])
    firstframe = np.zeros([ntrials+1])
    for i, x in exptevents.loc[pp].iterrows():
        t = x['Trial'] - 1
        s = x['name'].split(",[")
        p = eval("["+s[1])
        # print("{0} p=[{1}".format(i,s[1]))
        timestamp[t] = p[0]
        firstframe[t] = int(p[1])
    pp = ['PUPILSTOP' in x['name'] for i, x in exptevents.iterrows()]
    lastidx = np.argwhere(pp)[-1]

    s = exptevents.iloc[lastidx[0]]['name'].split(",[")
    p = eval("[" + s[1])
    timestamp[-1] = p[0]
    firstframe[-1] = int(p[1])

    # align pupil with other events, probably by
    # removing extra bins from between trials
    ff = exptevents['name'].str.startswith('TRIALSTART')
    start_events = exptevents.loc[ff, ['start']].reset_index()
    start_events['StartBin'] = (
            np.round(start_events['start'] * rasterfs)
            ).astype(int)
    start_e = list(start_events['StartBin'])
    ff = (exptevents['name'] == 'TRIALSTOP')
    stop_events = exptevents.loc[ff, ['start']].reset_index()
    stop_events['StopBin'] = (
            np.round(stop_events['start'] * rasterfs)
            ).astype(int)
    stop_e = list(stop_events['StopBin'])

    # calculate frame count and duration of each trial
    duration = np.diff(timestamp) * 24*60*60
    frame_count = np.diff(firstframe)

    # warp/resample each trial to compensate for dropped frames
    strialidx = np.zeros([ntrials + 1])
    big_rs = np.array([])
    all_fs = np.empty([ntrials])

    for ii in range(0, ntrials):
        d = returned_measurement[
                int(firstframe[ii]):int(firstframe[ii]+frame_count[ii]), 0
                ]
        fs = frame_count[ii] / duration[ii]
        all_fs[ii] = fs
        t = np.arange(0, len(d)) / fs
        if pupil_eyespeed:
            d = d*fs #convert to px/s before resampling
        ti = np.arange(
                (1/rasterfs)/2, duration[ii]+(1/rasterfs)/2, 1/rasterfs
                )
        # print("{0} len(d)={1} len(ti)={2} fs={3}"
        #       .format(ii,len(d),len(ti),fs))
        di = np.interp(ti, t, d)
        big_rs = np.concatenate((big_rs, di), axis=0)
        if (ii < ntrials-1) and (len(big_rs) > start_e[ii+1]):
            big_rs = big_rs[:start_e[ii+1]]
        elif ii == ntrials-1:
            big_rs = big_rs[:stop_e[ii]]
        strialidx[ii+1] = len(big_rs)

    if pupil_median:
        kernel_size = int(round(pupil_median*rasterfs/2)*2+1)
        big_rs = scipy.signal.medfilt(big_rs, kernel_size=kernel_size)

    # shift pupil (or eye speed) trace by offset, usually 0.75 sec
    offset_frames = int(pupil_offset*rasterfs)
    big_rs = np.roll(big_rs, -offset_frames)
    big_rs[-offset_frames:] = np.nan

    # shape to 1 x T to match NEMS signal specs
    big_rs = big_rs[np.newaxis, :]

    if pupil_mm:
        #convert measurements from pixels to mm
        eye_width_px = matdata['pupil_data']['results'][0][0]['eye_width'][0][0][0]
        eye_width_mm = matdata['pupil_data']['params'][0][0]['eye_width_mm'][0][0][0]
        big_rs = big_rs*(eye_width_mm/eye_width_px)

    if verbose:
        #plot framerate for each trial (for checking camera performance)
        plt.figure()
        plt.plot(all_fs.T)
        plt.xlabel('Trial')
        plt.ylabel('Sampling rate (Hz)')

    if verbose:
        plt.show()

    return big_rs, strialidx
